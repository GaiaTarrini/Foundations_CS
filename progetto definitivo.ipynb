{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to work on the files:\n",
    "*  [Books](https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Books.csv.gz)\n",
    "*  [Book ratings](https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Book-Ratings.csv.gz)\n",
    "*  [Users](https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Users.csv.gz)\n",
    "*  [Goodbooks books](https://github.com/gdv/foundationsCS/raw/master/progetti/2021/goodbooks.csv.gz)\n",
    "*  [Goodbooks ratings](https://github.com/gdv/foundationsCS/raw/master/progetti/2021/goodbooks-ratings.csv.gz)\n",
    "\n",
    "### Notes\n",
    "\n",
    "1.    It is mandatory to use GitHub for developing the project.\n",
    "1.    The project must be a jupyter notebook.\n",
    "1.    There is no restriction on the libraries that can be used, nor on the Python version.\n",
    "1.    To read those files, you need to use the `encoding = 'latin-1'` option.\n",
    "1.    All questions on the project **must** be asked in a public channel on [Zulip](https://focs.zulipchat.com), otherwise no  answer will be given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Svolgimento progetto\n",
    "\n",
    "### Bagnasco Anna - Tarrini Gaia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per prima cosa, importiamo la libreria pandas necessaria allo svolgimento del progetto stesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successivamente, carichiamo i file necessari allo svolgimento del progetto e assegniamo loro i seguenti nomi:\n",
    "- books --> books\n",
    "- book ratings --> booksR\n",
    "- users --> users\n",
    "- goodbooks books --> gbB\n",
    "- goodbooks ratings --> gbR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author Year-Of-Publication                   Publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = pd.read_csv(\"https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Books.csv.gz\", sep = ';', encoding = 'latin-1', compression = 'gzip', low_memory =  False)\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booksR = pd.read_csv(\"https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Book-Ratings.csv.gz\", sep = ';', encoding = 'latin-1', compression = 'gzip', low_memory =  False)\n",
    "booksR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID                            Location   Age\n",
       "0        1                  nyc, new york, usa   NaN\n",
       "1        2           stockton, california, usa  18.0\n",
       "2        3     moscow, yukon territory, russia   NaN\n",
       "3        4           porto, v.n.gaia, portugal  17.0\n",
       "4        5  farnborough, hants, united kingdom   NaN"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(\"https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Users.csv.gz\", sep = ';', encoding = 'latin-1', compression = 'gzip', low_memory =  False)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4942365</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>...</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4800065</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>226</td>\n",
       "      <td>316015849</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>...</td>\n",
       "      <td>3866839</td>\n",
       "      <td>3916824</td>\n",
       "      <td>95009</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2657</td>\n",
       "      <td>2657</td>\n",
       "      <td>3275794</td>\n",
       "      <td>487</td>\n",
       "      <td>61120081</td>\n",
       "      <td>9.780061e+12</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>...</td>\n",
       "      <td>3198671</td>\n",
       "      <td>3340896</td>\n",
       "      <td>72586</td>\n",
       "      <td>60427</td>\n",
       "      <td>117415</td>\n",
       "      <td>446835</td>\n",
       "      <td>1001952</td>\n",
       "      <td>1714267</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4671</td>\n",
       "      <td>4671</td>\n",
       "      <td>245494</td>\n",
       "      <td>1356</td>\n",
       "      <td>743273567</td>\n",
       "      <td>9.780743e+12</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>...</td>\n",
       "      <td>2683664</td>\n",
       "      <td>2773745</td>\n",
       "      <td>51992</td>\n",
       "      <td>86236</td>\n",
       "      <td>197621</td>\n",
       "      <td>606158</td>\n",
       "      <td>936012</td>\n",
       "      <td>947718</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  goodreads_book_id  best_book_id  work_id  books_count       isbn  \\\n",
       "0        1            2767052       2767052  2792775          272  439023483   \n",
       "1        2                  3             3  4640799          491  439554934   \n",
       "2        3              41865         41865  3212258          226  316015849   \n",
       "3        4               2657          2657  3275794          487   61120081   \n",
       "4        5               4671          4671   245494         1356  743273567   \n",
       "\n",
       "         isbn13                       authors  original_publication_year  \\\n",
       "0  9.780439e+12               Suzanne Collins                     2008.0   \n",
       "1  9.780440e+12  J.K. Rowling, Mary GrandPrÃ©                     1997.0   \n",
       "2  9.780316e+12               Stephenie Meyer                     2005.0   \n",
       "3  9.780061e+12                    Harper Lee                     1960.0   \n",
       "4  9.780743e+12           F. Scott Fitzgerald                     1925.0   \n",
       "\n",
       "                             original_title  ... ratings_count  \\\n",
       "0                          The Hunger Games  ...       4780653   \n",
       "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
       "2                                  Twilight  ...       3866839   \n",
       "3                     To Kill a Mockingbird  ...       3198671   \n",
       "4                          The Great Gatsby  ...       2683664   \n",
       "\n",
       "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
       "0            4942365                   155254      66715     127936   \n",
       "1            4800065                    75867      75504     101676   \n",
       "2            3916824                    95009     456191     436802   \n",
       "3            3340896                    72586      60427     117415   \n",
       "4            2773745                    51992      86236     197621   \n",
       "\n",
       "   ratings_3  ratings_4  ratings_5  \\\n",
       "0     560092    1481305    2706317   \n",
       "1     455024    1156318    3011543   \n",
       "2     793319     875073    1355439   \n",
       "3     446835    1001952    1714267   \n",
       "4     606158     936012     947718   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "1  https://images.gr-assets.com/books/1474154022m...   \n",
       "2  https://images.gr-assets.com/books/1361039443m...   \n",
       "3  https://images.gr-assets.com/books/1361975680m...   \n",
       "4  https://images.gr-assets.com/books/1490528560m...   \n",
       "\n",
       "                                     small_image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603s...  \n",
       "1  https://images.gr-assets.com/books/1474154022s...  \n",
       "2  https://images.gr-assets.com/books/1361039443s...  \n",
       "3  https://images.gr-assets.com/books/1361975680s...  \n",
       "4  https://images.gr-assets.com/books/1490528560s...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbB = pd.read_csv(\"https://github.com/gdv/foundationsCS/raw/master/progetti/2021/goodbooks.csv.gz\", sep = ',', encoding = 'latin-1', compression = 'gzip', low_memory =  False)\n",
    "gbB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9296</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2318</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        1      258       5\n",
       "1        2     4081       4\n",
       "2        2      260       5\n",
       "3        2     9296       5\n",
       "4        2     2318       3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbR = pd.read_csv(\"https://github.com/gdv/foundationsCS/raw/master/progetti/2021/goodbooks-ratings.csv.gz\", sep = ',', encoding = 'latin-1', compression = 'gzip', low_memory =  False)\n",
    "gbR.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso, analizziamo i dati contenuti all'interno dei dataframe, utilizzando principalmente i comandi:\n",
    "- .shape --> per vedere il numero di righe e di colonne\n",
    "- .columns --> per vedere i nomi di tutte le colonne \n",
    "\n",
    "Per non rendere troppo lungo lo svolgimento del progetto, non riportiamo l'applicazione dei comandi sopracitati ad ogni dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Normalize the location field of *Users* dataset, splitting into city, region, country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Per prima cosa, splittiamo la colonna _Location_ in tre colonne _City_, _Region_ e _Country_ creandole ed aggiungendole al dataframe _users_. <br>\n",
    "2. Successivamente, per eliminare la colonna _Location_ senza perdere traccia del suo contenuto, copiamo il dataframe _users_ nel dataframe _usersN_ (users normalized) in cui, al suo posto, manteniamo solo le colonne appena create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nyc</td>\n",
       "      <td>new york</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "      <td>stockton</td>\n",
       "      <td>california</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>moscow</td>\n",
       "      <td>yukon territory</td>\n",
       "      <td>russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "      <td>porto</td>\n",
       "      <td>v.n.gaia</td>\n",
       "      <td>portugal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>farnborough</td>\n",
       "      <td>hants</td>\n",
       "      <td>united kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID                            Location   Age         City  \\\n",
       "0        1                  nyc, new york, usa   NaN          nyc   \n",
       "1        2           stockton, california, usa  18.0     stockton   \n",
       "2        3     moscow, yukon territory, russia   NaN       moscow   \n",
       "3        4           porto, v.n.gaia, portugal  17.0        porto   \n",
       "4        5  farnborough, hants, united kingdom   NaN  farnborough   \n",
       "\n",
       "             Region          Country  \n",
       "0          new york              usa  \n",
       "1        california              usa  \n",
       "2   yukon territory           russia  \n",
       "3          v.n.gaia         portugal  \n",
       "4             hants   united kingdom  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passo 1\n",
    "users[['City', 'Region', 'Country']] = users['Location'].str.split(pat =',', n = 2, expand = True)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nyc</td>\n",
       "      <td>new york</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>stockton</td>\n",
       "      <td>california</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>moscow</td>\n",
       "      <td>yukon territory</td>\n",
       "      <td>russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>porto</td>\n",
       "      <td>v.n.gaia</td>\n",
       "      <td>portugal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>farnborough</td>\n",
       "      <td>hants</td>\n",
       "      <td>united kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID   Age         City            Region          Country\n",
       "0        1   NaN          nyc          new york              usa\n",
       "1        2  18.0     stockton        california              usa\n",
       "2        3   NaN       moscow   yukon territory           russia\n",
       "3        4  17.0        porto          v.n.gaia         portugal\n",
       "4        5   NaN  farnborough             hants   united kingdom"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passo 2\n",
    "usersN = users.drop('Location', axis = 1)\n",
    "usersN.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For each book in the *Books* dataset, compute its average rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Per prima cosa, effettuiamo un merge tra i dataframe _books_ e _booksR_: tale join deve essere sinistro in modo tale da non perdere nessuna istanza di _books_; la chiave che utilizziamo è data dalla colonna _ISBN_ perchè rappresenta il codice identificativo univoco di ogni libro.\n",
    "2. Successivamente, raggruppiamo per _ISBN_ (per lo stesso motivo precedente), prendiamo solamente la colonna _Book-Rating_ della quale effettuiamo la media richiesta.\n",
    "\n",
    "Per fare tali operazioni abbiamo innanzitutto visualizzato solamente l'_ISBN_ con la relativa media (Metodo A) e successivamente abbiamo deciso di salvare tale risultato; per fare ciò, abbiamo aggiunto la colonna _Book average rating_ al dataframe _books_ (Metodo B). <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ISBN\n",
       "0000913154    8.0\n",
       "0001010565    0.0\n",
       "0001046438    9.0\n",
       "0001046713    0.0\n",
       "000104687X    6.0\n",
       "             ... \n",
       "B000234N76    0.0\n",
       "B000234NC6    0.0\n",
       "B00029DGGO    0.0\n",
       "B0002JV9PY    0.0\n",
       "B0002K6K8O    0.0\n",
       "Name: Book-Rating, Length: 271359, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Metodo A\n",
    "#Passo 1:\n",
    "booksM = pd.merge(books, booksR, how = 'left', on = 'ISBN')\n",
    "#Passo 2:\n",
    "booksM.groupby('ISBN')['Book-Rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>Book average rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author Year-Of-Publication                   Publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  Book average rating  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...                  8.0  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...                  0.0  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...                  9.0  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...                  0.0  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...                  6.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Metodo B (in cui i passi 1 e 2 sono un'unica riga di comando)\n",
    "books['Book average rating'] = list(pd.merge(books, booksR, how = 'left', on = 'ISBN').groupby('ISBN')['Book-Rating'].mean())\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For each book in the *GoodBooks* dataset, compute its average rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Visualizziamo i nomi di tutte le colonne del dataframe _gbB_.\n",
    "2. Mostriamo i valori della colonna _average_rating_ per rispondere alla quesito posto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['book_id', 'goodreads_book_id', 'best_book_id', 'work_id',\n",
       "       'books_count', 'isbn', 'isbn13', 'authors', 'original_publication_year',\n",
       "       'original_title', 'title', 'language_code', 'average_rating',\n",
       "       'ratings_count', 'work_ratings_count', 'work_text_reviews_count',\n",
       "       'ratings_1', 'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5',\n",
       "       'image_url', 'small_image_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passo 1\n",
    "gbB.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4.34\n",
       "1     4.44\n",
       "2     3.57\n",
       "3     4.25\n",
       "4     3.89\n",
       "      ... \n",
       "94    4.06\n",
       "95    3.88\n",
       "96    3.98\n",
       "97    4.22\n",
       "98    3.87\n",
       "Name: average_rating, Length: 99, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passo 2\n",
    "gbB['average_rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Merge together all rows sharing the same book title, author and publisher. We will call the resulting datset `merged books`. The books that have not been merged together will not appear in `merged books`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Per prima cosa, grouppiamo il dataframe _books_ per le colonne _'Book-Title', 'Book-Author', 'Publisher'_ e contiamo il numero righe che contengono gli stessi valori di questi tre attributi.\n",
    "2. Salviamo nel dataframe _merged_books_ solamente le righe che compaiono più di una volta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>!%@ (A Nutshell handbook)</td>\n",
       "      <td>Donnalyn Frey</td>\n",
       "      <td>O'Reilly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>'A Hell of a Place to Lose a Cow': An American...</td>\n",
       "      <td>Tim Brookes</td>\n",
       "      <td>National Geographic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>10,000 dreams interpreted: A dictionary of dreams</td>\n",
       "      <td>Gustavus Hindman Miller</td>\n",
       "      <td>Barnes &amp;amp; Nobles Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>465</td>\n",
       "      <td>101 Famous Poems</td>\n",
       "      <td>Roy J. Cook</td>\n",
       "      <td>McGraw-Hill/Contemporary Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>713</td>\n",
       "      <td>15 Houseplants Even You Can't Kill</td>\n",
       "      <td>Joe Elder</td>\n",
       "      <td>Berkley Pub Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>265525</td>\n",
       "      <td>Zia</td>\n",
       "      <td>Scott O'Dell</td>\n",
       "      <td>Laurel-Leaf Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>265526</td>\n",
       "      <td>Zia</td>\n",
       "      <td>Scott O'Dell</td>\n",
       "      <td>Yearling Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>265562</td>\n",
       "      <td>Zimmermann Telegram</td>\n",
       "      <td>Barbara Tuchman</td>\n",
       "      <td>Ballantine Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>265625</td>\n",
       "      <td>Zoids Chaotic Century (Zoids: Chaotic Century ...</td>\n",
       "      <td>Michiro Ueyama</td>\n",
       "      <td>Viz Comics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4724</th>\n",
       "      <td>266117</td>\n",
       "      <td>Ã?Ã?berleben in der WÃ?ÃÂ¼ste Danakil.</td>\n",
       "      <td>RÃ?ÃÂ¼diger Nehberg</td>\n",
       "      <td>Piper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4725 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                         Book-Title  \\\n",
       "0         41                          !%@ (A Nutshell handbook)   \n",
       "1         59  'A Hell of a Place to Lose a Cow': An American...   \n",
       "2        255  10,000 dreams interpreted: A dictionary of dreams   \n",
       "3        465                                   101 Famous Poems   \n",
       "4        713                 15 Houseplants Even You Can't Kill   \n",
       "...      ...                                                ...   \n",
       "4720  265525                                                Zia   \n",
       "4721  265526                                                Zia   \n",
       "4722  265562                                Zimmermann Telegram   \n",
       "4723  265625  Zoids Chaotic Century (Zoids: Chaotic Century ...   \n",
       "4724  266117         Ã?Ã?berleben in der WÃ?ÃÂ¼ste Danakil.   \n",
       "\n",
       "                  Book-Author                       Publisher  \n",
       "0               Donnalyn Frey                        O'Reilly  \n",
       "1                 Tim Brookes             National Geographic  \n",
       "2     Gustavus Hindman Miller       Barnes &amp; Nobles Books  \n",
       "3                 Roy J. Cook  McGraw-Hill/Contemporary Books  \n",
       "4                   Joe Elder               Berkley Pub Group  \n",
       "...                       ...                             ...  \n",
       "4720             Scott O'Dell               Laurel-Leaf Books  \n",
       "4721             Scott O'Dell                  Yearling Books  \n",
       "4722          Barbara Tuchman                Ballantine Books  \n",
       "4723           Michiro Ueyama                      Viz Comics  \n",
       "4724    RÃ?ÃÂ¼diger Nehberg                           Piper  \n",
       "\n",
       "[4725 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passo 1\n",
    "aux = books.groupby(['Book-Title', 'Book-Author', 'Publisher'], as_index = False).count() \n",
    "#Passo 2\n",
    "merged_books = aux[aux['ISBN']>1][['Book-Title', 'Book-Author', 'Publisher']].reset_index()\n",
    "merged_books "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. For each book in `merged books` compute its average rating.\n",
    "\n",
    "The average is computed considering all books in `books` that have been merged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Per prima cosa, effettuiamo il merge dei dataframe _books_ e _merged_books_ in modo tale da creare un unico dataframe chiamato _aux2_ usando come chiave la lista di attributi _'Book-Title', 'Book-Author', 'Publisher'_ \n",
    "2. Per calcolare l'average rating richiesto, gruppiamo il dataframe _aux2_ rispetto alla chiave precedente e ne calcoliamo la media, prendendo solamente la colonna che ci interessa _'Book average rating'_. Questo risultato lo inseriamo in una nuova colonna all'interno del dataframe _merged_books_ chiamandola _Average rating_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Average rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>!%@ (A Nutshell handbook)</td>\n",
       "      <td>Donnalyn Frey</td>\n",
       "      <td>O'Reilly</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>'A Hell of a Place to Lose a Cow': An American...</td>\n",
       "      <td>Tim Brookes</td>\n",
       "      <td>National Geographic</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>10,000 dreams interpreted: A dictionary of dreams</td>\n",
       "      <td>Gustavus Hindman Miller</td>\n",
       "      <td>Barnes &amp;amp; Nobles Books</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>465</td>\n",
       "      <td>101 Famous Poems</td>\n",
       "      <td>Roy J. Cook</td>\n",
       "      <td>McGraw-Hill/Contemporary Books</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>713</td>\n",
       "      <td>15 Houseplants Even You Can't Kill</td>\n",
       "      <td>Joe Elder</td>\n",
       "      <td>Berkley Pub Group</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>265525</td>\n",
       "      <td>Zia</td>\n",
       "      <td>Scott O'Dell</td>\n",
       "      <td>Laurel-Leaf Books</td>\n",
       "      <td>1.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>265526</td>\n",
       "      <td>Zia</td>\n",
       "      <td>Scott O'Dell</td>\n",
       "      <td>Yearling Books</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>265562</td>\n",
       "      <td>Zimmermann Telegram</td>\n",
       "      <td>Barbara Tuchman</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>2.994318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>265625</td>\n",
       "      <td>Zoids Chaotic Century (Zoids: Chaotic Century ...</td>\n",
       "      <td>Michiro Ueyama</td>\n",
       "      <td>Viz Comics</td>\n",
       "      <td>2.792857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4724</th>\n",
       "      <td>266117</td>\n",
       "      <td>Ã?Ã?berleben in der WÃ?ÃÂ¼ste Danakil.</td>\n",
       "      <td>RÃ?ÃÂ¼diger Nehberg</td>\n",
       "      <td>Piper</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4725 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                         Book-Title  \\\n",
       "0         41                          !%@ (A Nutshell handbook)   \n",
       "1         59  'A Hell of a Place to Lose a Cow': An American...   \n",
       "2        255  10,000 dreams interpreted: A dictionary of dreams   \n",
       "3        465                                   101 Famous Poems   \n",
       "4        713                 15 Houseplants Even You Can't Kill   \n",
       "...      ...                                                ...   \n",
       "4720  265525                                                Zia   \n",
       "4721  265526                                                Zia   \n",
       "4722  265562                                Zimmermann Telegram   \n",
       "4723  265625  Zoids Chaotic Century (Zoids: Chaotic Century ...   \n",
       "4724  266117         Ã?Ã?berleben in der WÃ?ÃÂ¼ste Danakil.   \n",
       "\n",
       "                  Book-Author                       Publisher  Average rating  \n",
       "0               Donnalyn Frey                        O'Reilly        4.000000  \n",
       "1                 Tim Brookes             National Geographic        3.500000  \n",
       "2     Gustavus Hindman Miller       Barnes &amp; Nobles Books        7.500000  \n",
       "3                 Roy J. Cook  McGraw-Hill/Contemporary Books        8.333333  \n",
       "4                   Joe Elder               Berkley Pub Group        1.250000  \n",
       "...                       ...                             ...             ...  \n",
       "4720             Scott O'Dell               Laurel-Leaf Books        1.825000  \n",
       "4721             Scott O'Dell                  Yearling Books        0.000000  \n",
       "4722          Barbara Tuchman                Ballantine Books        2.994318  \n",
       "4723           Michiro Ueyama                      Viz Comics        2.792857  \n",
       "4724    RÃ?ÃÂ¼diger Nehberg                           Piper        3.714286  \n",
       "\n",
       "[4725 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passo 1\n",
    "aux2 = pd.merge(books, merged_books, on = ['Book-Title', 'Book-Author', 'Publisher'])\n",
    "#Passo 2\n",
    "merged_books['Average rating'] = aux2.groupby(['Book-Title', 'Book-Author', 'Publisher'], as_index = False).mean()['Book average rating']\n",
    "\n",
    "merged_books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. For each book in `merged books` compute the minimum and maximum of the average ratings over all corresponding books in the `books` dataset.\n",
    "\n",
    "Hence for each book in `merged books` we will have exactly two values (a minimum and a maximum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando il dataframe _merged_books_ creato precedentemente, ricaviamo il minimo e il massimo valore dell'average rating in questo modo:\n",
    "1. effettuiamo un merge tra i dataframes _books_ e _merged_books_ utilizzando come chiave gli attributi _'Book-Title', 'Book-Author', 'Publisher'_\n",
    "2. gruppiamo il dataframe ottenuto rispetto agli stessi attributi precedenti e calcoliamo il minimo o il massimo della colonna di nostro interesse _'Book average rating'_, salvando il risultato in due nuove colonne del dataframe _merged_books_, una per il minimo e una per il massimo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Average rating</th>\n",
       "      <th>Min average rating</th>\n",
       "      <th>Max average rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>!%@ (A Nutshell handbook)</td>\n",
       "      <td>Donnalyn Frey</td>\n",
       "      <td>O'Reilly</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>'A Hell of a Place to Lose a Cow': An American...</td>\n",
       "      <td>Tim Brookes</td>\n",
       "      <td>National Geographic</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>10,000 dreams interpreted: A dictionary of dreams</td>\n",
       "      <td>Gustavus Hindman Miller</td>\n",
       "      <td>Barnes &amp;amp; Nobles Books</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>465</td>\n",
       "      <td>101 Famous Poems</td>\n",
       "      <td>Roy J. Cook</td>\n",
       "      <td>McGraw-Hill/Contemporary Books</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>713</td>\n",
       "      <td>15 Houseplants Even You Can't Kill</td>\n",
       "      <td>Joe Elder</td>\n",
       "      <td>Berkley Pub Group</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>265525</td>\n",
       "      <td>Zia</td>\n",
       "      <td>Scott O'Dell</td>\n",
       "      <td>Laurel-Leaf Books</td>\n",
       "      <td>1.825000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>2.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>265526</td>\n",
       "      <td>Zia</td>\n",
       "      <td>Scott O'Dell</td>\n",
       "      <td>Yearling Books</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>265562</td>\n",
       "      <td>Zimmermann Telegram</td>\n",
       "      <td>Barbara Tuchman</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>2.994318</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>4.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>265625</td>\n",
       "      <td>Zoids Chaotic Century (Zoids: Chaotic Century ...</td>\n",
       "      <td>Michiro Ueyama</td>\n",
       "      <td>Viz Comics</td>\n",
       "      <td>2.792857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4724</th>\n",
       "      <td>266117</td>\n",
       "      <td>Ã?Ã?berleben in der WÃ?ÃÂ¼ste Danakil.</td>\n",
       "      <td>RÃ?ÃÂ¼diger Nehberg</td>\n",
       "      <td>Piper</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4725 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                         Book-Title  \\\n",
       "0         41                          !%@ (A Nutshell handbook)   \n",
       "1         59  'A Hell of a Place to Lose a Cow': An American...   \n",
       "2        255  10,000 dreams interpreted: A dictionary of dreams   \n",
       "3        465                                   101 Famous Poems   \n",
       "4        713                 15 Houseplants Even You Can't Kill   \n",
       "...      ...                                                ...   \n",
       "4720  265525                                                Zia   \n",
       "4721  265526                                                Zia   \n",
       "4722  265562                                Zimmermann Telegram   \n",
       "4723  265625  Zoids Chaotic Century (Zoids: Chaotic Century ...   \n",
       "4724  266117         Ã?Ã?berleben in der WÃ?ÃÂ¼ste Danakil.   \n",
       "\n",
       "                  Book-Author                       Publisher  Average rating  \\\n",
       "0               Donnalyn Frey                        O'Reilly        4.000000   \n",
       "1                 Tim Brookes             National Geographic        3.500000   \n",
       "2     Gustavus Hindman Miller       Barnes &amp; Nobles Books        7.500000   \n",
       "3                 Roy J. Cook  McGraw-Hill/Contemporary Books        8.333333   \n",
       "4                   Joe Elder               Berkley Pub Group        1.250000   \n",
       "...                       ...                             ...             ...   \n",
       "4720             Scott O'Dell               Laurel-Leaf Books        1.825000   \n",
       "4721             Scott O'Dell                  Yearling Books        0.000000   \n",
       "4722          Barbara Tuchman                Ballantine Books        2.994318   \n",
       "4723           Michiro Ueyama                      Viz Comics        2.792857   \n",
       "4724    RÃ?ÃÂ¼diger Nehberg                           Piper        3.714286   \n",
       "\n",
       "      Min average rating  Max average rating  \n",
       "0               0.000000               8.000  \n",
       "1               0.000000               7.000  \n",
       "2               7.000000               8.000  \n",
       "3               7.000000               9.000  \n",
       "4               0.000000               2.500  \n",
       "...                  ...                 ...  \n",
       "4720            1.400000               2.250  \n",
       "4721            0.000000               0.000  \n",
       "4722            1.363636               4.625  \n",
       "4723            0.000000               7.000  \n",
       "4724            3.428571               4.000  \n",
       "\n",
       "[4725 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passo 1\n",
    "aux3 = pd.merge(books, merged_books, on = ['Book-Title', 'Book-Author', 'Publisher'])\n",
    "aux4 = pd.merge(books, merged_books, on = ['Book-Title', 'Book-Author', 'Publisher'])\n",
    "#Passo 2\n",
    "merged_books['Min average rating'] = aux3.groupby(['Book-Title', 'Book-Author', 'Publisher'], as_index = False).min()['Book average rating']\n",
    "merged_books['Max average rating'] = aux4.groupby(['Book-Title', 'Book-Author', 'Publisher'], as_index = False).max()['Book average rating']\n",
    "merged_books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. For each book in `goodbooks`, compute the list of its authors. Assuming that the number of reviews with a text (column `work_text_reviews_count`) is split equally among all authors, find for each authors the total number of reviews with a text. We will call this quantity the *shared number of reviews with a text*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per prima cosa scriviamo una funzione chiamata _fun_ con i seguenti parametri: <br>\n",
    "    - colonna = colonna autori di gbB <br>\n",
    "    - id = colonna degli id-books di gbB <br>\n",
    "    - count review = colonna work_text_reviews_count di gbB <br>\n",
    "\n",
    "e che segue i seguenti passi: <br>\n",
    "- Per trovare la lista degli autori senza ripetizioni: <br>\n",
    "    -- PASSO 1: utilizziamo un ciclo for (su k) da ripetere per tutta la lunghezza della colonna _gbB['authors']_ in cui:\n",
    "        1. salviamo nella lista provv gli autori di ciascun libro usando il metodo .split con separatore ','\n",
    "        2. aggiungiamo alla lista del numero di autori di ciascun libro la lunghezza della colonna che splittiamo          \n",
    "            al punto 1, in modo tale da sapere quanti autori ci sono per ogni libro\n",
    "        3. salviamo nel dizionario 'authors_all':\n",
    "            - la variabile di iterazione\n",
    "            - la lista degli autori di ciascun libro\n",
    "            - il numero di autori di ciascun libro\n",
    "            - il valore della colonna 'work_text_reviews_count' di gbB diviso il numero di autori per ogni libro\n",
    "     -- PASSO 2: utilizziamo un altro ciclo for (su i) all'interno del precedente per eliminare gli eventuali spazi davanti ai nomi degli autori e risolvere il problema che lo stesso autore, con o senza spazi, viene visualizzato due volte (e noi lo vogliamo ripetuto una sola volta in 'authors_list')\n",
    "\n",
    "- Per rispondere alla domanda completa: <br>\n",
    "     -- PASSO 3: utilizziamo un altro ciclo for (su j) per creare ed inizializzare il dizionario degli autori 'authors_dic' che contiene:\n",
    "             - la variabile di iterazione\n",
    "             - il nome dell'autore\n",
    "             - il valore 0, che poi verrà sostituito dal 'total number of reviews with a text'\n",
    "     -- PASSO 4: utilizziamo un altro ciclo for (su j) che itera sulla lunghezza del dizionario 'authors_all' e:\n",
    "         1. PASSO 5: con un ciclo for (su i) che itera sulla lunghezza della lista degli autori di ogni riga di\n",
    "             'authors_all' che fissa ogni autore di tale lista\n",
    "         2. PASSO 6: all'interno di quest'ultimo ciclo, creiamo un ulteriore ciclo for (su k) sulla lunghezza di\n",
    "             'authors_dic' in cui se ciascun autore di 'authors_dic' è uguale all'autore fissato in precedenza\n",
    "             allora aggiorniamo nel dizionario 'authors_dic' il valore che era stato precedentemente fissato a 0 in\n",
    "             modo tale da ottenere la somma desiderata\n",
    "\n",
    "\n",
    "- Alla fine, dopo che chiamiamo la funzione (PASSO 7) visualizziamo: <br>\n",
    "    -- _authors_all_ per avere la lista degli autori di ciascun libro --> PASSO 8 <br>\n",
    "    -- _authors_dic_ per avere il valore totale di _review_with_text_ di ogni autore --> PASSO 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_list = []\n",
    "authors_number = []\n",
    "authors_dic = {}\n",
    "authors_all = {}\n",
    "\n",
    "#colonna = colonna autori di gbB\n",
    "#id = colonna degli id-books di gbB\n",
    "#count review = colonna work_text_reviews_count di gbB\n",
    "def fun(colonna, id, countReview):\n",
    "    provv = []\n",
    "    aux = []\n",
    "    \n",
    "    #Passo 1\n",
    "    for k in range(0, len(colonna)):\n",
    "        provv = colonna[k].split(sep=',')\n",
    "        authors_number.append(len(colonna[k].split(sep=',')))\n",
    "        authors_all[k] = [k, provv, authors_number[k], countReview[k]/authors_number[k]]\n",
    "\n",
    "        #Passo 2\n",
    "        for i in range(len(provv)):\n",
    "            provv[i] = provv[i].strip()\n",
    "            if provv[i] not in authors_list:\n",
    "                 authors_list.append((provv[i]))\n",
    "    \n",
    "    #Passo 3\n",
    "    for j in range(len(authors_list)):\n",
    "        authors_dic[j] = [j, authors_list[j], float(0)]   \n",
    "    \n",
    "    #Passo 4\n",
    "    for j in range(len(authors_all)):\n",
    "        \n",
    "        #Passo 5\n",
    "        for i in range(len(authors_all[j][1])):\n",
    "            fisso = authors_all[j][1][i]\n",
    "            \n",
    "            #Passo 6\n",
    "            for k in range(len(authors_dic)):\n",
    "                if (authors_dic[k][1] ==  fisso):\n",
    "                    authors_dic[k][2] = authors_dic[k][2] +float(authors_all[j][3])\n",
    "                \n",
    "            \n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 7\n",
    "fun(gbB['authors'], gbB['book_id'], gbB['work_text_reviews_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, ['Suzanne Collins'], 1, 155254.0],\n",
       " 1: [1, ['J.K. Rowling', 'Mary GrandPrÃ©'], 2, 37933.5],\n",
       " 2: [2, ['Stephenie Meyer'], 1, 95009.0],\n",
       " 3: [3, ['Harper Lee'], 1, 72586.0],\n",
       " 4: [4, ['F. Scott Fitzgerald'], 1, 51992.0],\n",
       " 5: [5, ['John Green'], 1, 140739.0],\n",
       " 6: [6, ['J.R.R. Tolkien'], 1, 37653.0],\n",
       " 7: [7, ['J.D. Salinger'], 1, 44920.0],\n",
       " 8: [8, ['Dan Brown'], 1, 25112.0],\n",
       " 9: [9, ['Jane Austen'], 1, 49152.0],\n",
       " 10: [10, ['Khaled Hosseini'], 1, 59730.0],\n",
       " 11: [11, ['Veronica Roth'], 1, 101023.0],\n",
       " 12: [12,\n",
       "  ['George Orwell', 'Erich Fromm', 'CelÃ¢l Ã\\x9cster'],\n",
       "  3,\n",
       "  15172.666666666666],\n",
       " 13: [13, ['George Orwell'], 1, 35472.0],\n",
       " 14: [14,\n",
       "  ['Anne Frank', 'Eleanor Roosevelt', 'B.M. Mooyaart-Doubleday'],\n",
       "  3,\n",
       "  6941.666666666667],\n",
       " 15: [15, ['Stieg Larsson', 'Reg Keeland'], 2, 31271.5],\n",
       " 16: [16, ['Suzanne Collins'], 1, 88538.0],\n",
       " 17: [17, ['J.K. Rowling', 'Mary GrandPrÃ©', 'Rufus Beck'], 3, 12033.0],\n",
       " 18: [18, ['J.R.R. Tolkien'], 1, 15333.0],\n",
       " 19: [19, ['Suzanne Collins'], 1, 96274.0],\n",
       " 20: [20, ['J.K. Rowling', 'Mary GrandPrÃ©'], 2, 14342.5],\n",
       " 21: [21, ['Alice Sebold'], 1, 36642.0],\n",
       " 22: [22, ['J.K. Rowling', 'Mary GrandPrÃ©'], 2, 17086.0],\n",
       " 23: [23, ['J.K. Rowling', 'Mary GrandPrÃ©'], 2, 15542.0],\n",
       " 24: [24, ['J.K. Rowling', 'Mary GrandPrÃ©'], 2, 25971.0],\n",
       " 25: [25, ['Dan Brown'], 1, 41560.0],\n",
       " 26: [26, ['J.K. Rowling', 'Mary GrandPrÃ©'], 2, 13760.0],\n",
       " 27: [27, ['William Golding'], 1, 26886.0],\n",
       " 28: [28, ['William Shakespeare', 'Robert           Jackson'], 2, 7389.0],\n",
       " 29: [29, ['Gillian Flynn'], 1, 121614.0],\n",
       " 30: [30, ['Kathryn Stockett'], 1, 78204.0],\n",
       " 31: [31, ['John Steinbeck'], 1, 24642.0],\n",
       " 32: [32, ['Arthur Golden'], 1, 25605.0],\n",
       " 33: [33, ['E.L. James'], 1, 75437.0],\n",
       " 34: [34, ['Paulo Coelho', 'Alan R. Clarke'], 2, 27890.5],\n",
       " 35: [35, ['Lois Lowry'], 1, 54084.0],\n",
       " 36: [36, ['C.S. Lewis'], 1, 15186.0],\n",
       " 37: [37, ['Audrey Niffenegger'], 1, 43382.0],\n",
       " 38: [38, ['George R.R. Martin'], 1, 46205.0],\n",
       " 39: [39, ['Elizabeth Gilbert'], 1, 49714.0],\n",
       " 40: [40, ['Rick Riordan'], 1, 46006.0],\n",
       " 41: [41, ['Louisa May Alcott'], 1, 17090.0],\n",
       " 42: [42, ['Charlotte BrontÃ«', 'Michael Mason'], 2, 15606.0],\n",
       " 43: [43, ['Nicholas Sparks'], 1, 17279.0],\n",
       " 44: [44, ['Yann Martel'], 1, 42962.0],\n",
       " 45: [45, ['Sara Gruen'], 1, 55732.0],\n",
       " 46: [46, ['Markus Zusak'], 1, 93611.0],\n",
       " 47: [47, ['Ray Bradbury'], 1, 30694.0],\n",
       " 48: [48, ['Stephenie Meyer'], 1, 44020.0],\n",
       " 49: [49, ['Shel Silverstein'], 1, 9234.0],\n",
       " 50: [50, ['Cassandra Clare'], 1, 51589.0],\n",
       " 51: [51, ['Stephenie Meyer'], 1, 35216.0],\n",
       " 52: [52, ['Christopher Paolini'], 1, 18280.0],\n",
       " 53: [53, ['Douglas Adams'], 1, 20345.0],\n",
       " 54: [54, ['Aldous Huxley'], 1, 20095.0],\n",
       " 55: [55, ['Stephenie Meyer'], 1, 44550.0],\n",
       " 56: [56, ['Sue Monk Kidd'], 1, 26522.0],\n",
       " 57: [57, ['Mark Twain', 'John Seelye', 'Guy Cardwell'], 3, 4149.333333333333],\n",
       " 58: [58, ['E.B. White', 'Garth Williams', 'Rosemary Wells'], 3, 4348.0],\n",
       " 59: [59, ['Mark Haddon'], 1, 35796.0],\n",
       " 60: [60, ['Paula Hawkins'], 1, 93600.0],\n",
       " 61: [61, ['Philip Pullman'], 1, 14915.0],\n",
       " 62: [62, ['Emily BrontÃ«', 'Richard J. Dunn'], 2, 13078.5],\n",
       " 63: [63, ['Jodi Picoult'], 1, 30719.0],\n",
       " 64: [64, ['Kurt Vonnegut Jr.'], 1, 19646.0],\n",
       " 65: [65, ['Margaret Mitchell'], 1, 16050.0],\n",
       " 66: [66, ['Khaled Hosseini'], 1, 43645.0],\n",
       " 67: [67, ['Stephen Chbosky'], 1, 47116.0],\n",
       " 68: [68, ['Veronica Roth'], 1, 55873.0],\n",
       " 69: [69, ['Orson Scott Card'], 1, 38054.0],\n",
       " 70: [70,\n",
       "  ['Mary Wollstonecraft Shelley', 'Percy Bysshe Shelley', 'Maurice Hindle'],\n",
       "  3,\n",
       "  6664.333333333333],\n",
       " 71: [71, ['Stephen King'], 1, 14936.0],\n",
       " 72: [72, ['Stephenie Meyer'], 1, 39778.0],\n",
       " 73: [73, ['John Green'], 1, 47128.0],\n",
       " 74: [74, ['Helen Fielding'], 1, 8157.0],\n",
       " 75: [75, ['Jane Austen', 'Tony Tanner', 'Ros Ballaster'], 3, 3842.0],\n",
       " 76: [76, ['Louis Sachar', 'Louis Sachar'], 2, 7916.0],\n",
       " 77: [77, ['Lauren Weisberger'], 1, 8024.0],\n",
       " 78: [78,\n",
       "  ['Homer', 'Robert Fagles', 'E.V. Rieu', 'FrÃ©dÃ©ric Mugler', 'Bernard Knox'],\n",
       "  5,\n",
       "  1620.2],\n",
       " 79: [79,\n",
       "  ['Antoine de Saint-ExupÃ©ry',\n",
       "   'Richard Howard',\n",
       "   'Dom Marcos Barbosa',\n",
       "   'Melina Karakosta'],\n",
       "  4,\n",
       "  6134.25],\n",
       " 80: [80, ['Jeannette Walls'], 1, 40777.0],\n",
       " 81: [81, ['Jon Krakauer'], 1, 17299.0],\n",
       " 82: [82,\n",
       "  ['Charles Dickens', 'Richard Maxwell', 'Hablot Knight Browne'],\n",
       "  3,\n",
       "  4364.333333333333],\n",
       " 83: [83, ['Michael Crichton'], 1, 8143.0],\n",
       " 84: [84, ['Shel Silverstein'], 1, 14368.0],\n",
       " 85: [85, ['John Grisham'], 1, 4239.0],\n",
       " 86: [86, ['Elie Wiesel', 'Marion Wiesel'], 2, 11000.5],\n",
       " 87: [87, ['John Green'], 1, 42717.0],\n",
       " 88: [88, ['William Goldman'], 1, 15630.0],\n",
       " 89: [89, ['S.E. Hinton'], 1, 22662.0],\n",
       " 90: [90, ['James Dashner'], 1, 48942.0],\n",
       " 91: [91, ['Steven D. Levitt', 'Stephen J. Dubner'], 2, 6834.0],\n",
       " 92: [92, ['Frances Hodgson Burnett'], 1, 13054.0],\n",
       " 93: [93, ['Gabriel GarcÃ\\xada MÃ¡rquez', 'Gregory Rabassa'], 2, 10835.5],\n",
       " 94: [94, ['Oscar Wilde', 'Jeffrey Eugenides'], 2, 9823.5],\n",
       " 95: [95, ['E.L. James'], 1, 25287.0],\n",
       " 96: [96,\n",
       "  ['Bram Stoker', 'Nina Auerbach', 'David J. Skal'],\n",
       "  3,\n",
       "  5754.333333333333],\n",
       " 97: [97, ['Stieg Larsson', 'Reg Keeland'], 2, 15711.5],\n",
       " 98: [98, ['E.L. James'], 1, 28052.0]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passo 8\n",
    "authors_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 'Suzanne Collins', 340066.0],\n",
       " 1: [1, 'J.K. Rowling', 136668.0],\n",
       " 2: [2, 'Mary GrandPrÃ©', 136668.0],\n",
       " 3: [3, 'Stephenie Meyer', 258573.0],\n",
       " 4: [4, 'Harper Lee', 72586.0],\n",
       " 5: [5, 'F. Scott Fitzgerald', 51992.0],\n",
       " 6: [6, 'John Green', 230584.0],\n",
       " 7: [7, 'J.R.R. Tolkien', 52986.0],\n",
       " 8: [8, 'J.D. Salinger', 44920.0],\n",
       " 9: [9, 'Dan Brown', 66672.0],\n",
       " 10: [10, 'Jane Austen', 52994.0],\n",
       " 11: [11, 'Khaled Hosseini', 103375.0],\n",
       " 12: [12, 'Veronica Roth', 156896.0],\n",
       " 13: [13, 'George Orwell', 50644.666666666664],\n",
       " 14: [14, 'Erich Fromm', 15172.666666666666],\n",
       " 15: [15, 'CelÃ¢l Ã\\x9cster', 15172.666666666666],\n",
       " 16: [16, 'Anne Frank', 6941.666666666667],\n",
       " 17: [17, 'Eleanor Roosevelt', 6941.666666666667],\n",
       " 18: [18, 'B.M. Mooyaart-Doubleday', 6941.666666666667],\n",
       " 19: [19, 'Stieg Larsson', 46983.0],\n",
       " 20: [20, 'Reg Keeland', 46983.0],\n",
       " 21: [21, 'Rufus Beck', 12033.0],\n",
       " 22: [22, 'Alice Sebold', 36642.0],\n",
       " 23: [23, 'William Golding', 26886.0],\n",
       " 24: [24, 'William Shakespeare', 7389.0],\n",
       " 25: [25, 'Robert           Jackson', 7389.0],\n",
       " 26: [26, 'Gillian Flynn', 121614.0],\n",
       " 27: [27, 'Kathryn Stockett', 78204.0],\n",
       " 28: [28, 'John Steinbeck', 24642.0],\n",
       " 29: [29, 'Arthur Golden', 25605.0],\n",
       " 30: [30, 'E.L. James', 128776.0],\n",
       " 31: [31, 'Paulo Coelho', 27890.5],\n",
       " 32: [32, 'Alan R. Clarke', 27890.5],\n",
       " 33: [33, 'Lois Lowry', 54084.0],\n",
       " 34: [34, 'C.S. Lewis', 15186.0],\n",
       " 35: [35, 'Audrey Niffenegger', 43382.0],\n",
       " 36: [36, 'George R.R. Martin', 46205.0],\n",
       " 37: [37, 'Elizabeth Gilbert', 49714.0],\n",
       " 38: [38, 'Rick Riordan', 46006.0],\n",
       " 39: [39, 'Louisa May Alcott', 17090.0],\n",
       " 40: [40, 'Charlotte BrontÃ«', 15606.0],\n",
       " 41: [41, 'Michael Mason', 15606.0],\n",
       " 42: [42, 'Nicholas Sparks', 17279.0],\n",
       " 43: [43, 'Yann Martel', 42962.0],\n",
       " 44: [44, 'Sara Gruen', 55732.0],\n",
       " 45: [45, 'Markus Zusak', 93611.0],\n",
       " 46: [46, 'Ray Bradbury', 30694.0],\n",
       " 47: [47, 'Shel Silverstein', 23602.0],\n",
       " 48: [48, 'Cassandra Clare', 51589.0],\n",
       " 49: [49, 'Christopher Paolini', 18280.0],\n",
       " 50: [50, 'Douglas Adams', 20345.0],\n",
       " 51: [51, 'Aldous Huxley', 20095.0],\n",
       " 52: [52, 'Sue Monk Kidd', 26522.0],\n",
       " 53: [53, 'Mark Twain', 4149.333333333333],\n",
       " 54: [54, 'John Seelye', 4149.333333333333],\n",
       " 55: [55, 'Guy Cardwell', 4149.333333333333],\n",
       " 56: [56, 'E.B. White', 4348.0],\n",
       " 57: [57, 'Garth Williams', 4348.0],\n",
       " 58: [58, 'Rosemary Wells', 4348.0],\n",
       " 59: [59, 'Mark Haddon', 35796.0],\n",
       " 60: [60, 'Paula Hawkins', 93600.0],\n",
       " 61: [61, 'Philip Pullman', 14915.0],\n",
       " 62: [62, 'Emily BrontÃ«', 13078.5],\n",
       " 63: [63, 'Richard J. Dunn', 13078.5],\n",
       " 64: [64, 'Jodi Picoult', 30719.0],\n",
       " 65: [65, 'Kurt Vonnegut Jr.', 19646.0],\n",
       " 66: [66, 'Margaret Mitchell', 16050.0],\n",
       " 67: [67, 'Stephen Chbosky', 47116.0],\n",
       " 68: [68, 'Orson Scott Card', 38054.0],\n",
       " 69: [69, 'Mary Wollstonecraft Shelley', 6664.333333333333],\n",
       " 70: [70, 'Percy Bysshe Shelley', 6664.333333333333],\n",
       " 71: [71, 'Maurice Hindle', 6664.333333333333],\n",
       " 72: [72, 'Stephen King', 14936.0],\n",
       " 73: [73, 'Helen Fielding', 8157.0],\n",
       " 74: [74, 'Tony Tanner', 3842.0],\n",
       " 75: [75, 'Ros Ballaster', 3842.0],\n",
       " 76: [76, 'Louis Sachar', 15832.0],\n",
       " 77: [77, 'Lauren Weisberger', 8024.0],\n",
       " 78: [78, 'Homer', 1620.2],\n",
       " 79: [79, 'Robert Fagles', 1620.2],\n",
       " 80: [80, 'E.V. Rieu', 1620.2],\n",
       " 81: [81, 'FrÃ©dÃ©ric Mugler', 1620.2],\n",
       " 82: [82, 'Bernard Knox', 1620.2],\n",
       " 83: [83, 'Antoine de Saint-ExupÃ©ry', 6134.25],\n",
       " 84: [84, 'Richard Howard', 6134.25],\n",
       " 85: [85, 'Dom Marcos Barbosa', 6134.25],\n",
       " 86: [86, 'Melina Karakosta', 6134.25],\n",
       " 87: [87, 'Jeannette Walls', 40777.0],\n",
       " 88: [88, 'Jon Krakauer', 17299.0],\n",
       " 89: [89, 'Charles Dickens', 4364.333333333333],\n",
       " 90: [90, 'Richard Maxwell', 4364.333333333333],\n",
       " 91: [91, 'Hablot Knight Browne', 4364.333333333333],\n",
       " 92: [92, 'Michael Crichton', 8143.0],\n",
       " 93: [93, 'John Grisham', 4239.0],\n",
       " 94: [94, 'Elie Wiesel', 11000.5],\n",
       " 95: [95, 'Marion Wiesel', 11000.5],\n",
       " 96: [96, 'William Goldman', 15630.0],\n",
       " 97: [97, 'S.E. Hinton', 22662.0],\n",
       " 98: [98, 'James Dashner', 48942.0],\n",
       " 99: [99, 'Steven D. Levitt', 6834.0],\n",
       " 100: [100, 'Stephen J. Dubner', 6834.0],\n",
       " 101: [101, 'Frances Hodgson Burnett', 13054.0],\n",
       " 102: [102, 'Gabriel GarcÃ\\xada MÃ¡rquez', 10835.5],\n",
       " 103: [103, 'Gregory Rabassa', 10835.5],\n",
       " 104: [104, 'Oscar Wilde', 9823.5],\n",
       " 105: [105, 'Jeffrey Eugenides', 9823.5],\n",
       " 106: [106, 'Bram Stoker', 5754.333333333333],\n",
       " 107: [107, 'Nina Auerbach', 5754.333333333333],\n",
       " 108: [108, 'David J. Skal', 5754.333333333333]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passo 9\n",
    "authors_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, ['Suzanne Collins'], 1, 155254.0],\n",
       " 1: [1, ['J.K. Rowling', 'Mary GrandPrÃ©'], 2, 37933.5],\n",
       " 2: [2, ['Stephenie Meyer'], 1, 95009.0],\n",
       " 3: [3, ['Harper Lee'], 1, 72586.0],\n",
       " 4: [4, ['F. Scott Fitzgerald'], 1, 51992.0],\n",
       " 5: [5, ['John Green'], 1, 140739.0],\n",
       " 6: [6, ['J.R.R. Tolkien'], 1, 37653.0],\n",
       " 7: [7, ['J.D. Salinger'], 1, 44920.0],\n",
       " 8: [8, ['Dan Brown'], 1, 25112.0],\n",
       " 9: [9, ['Jane Austen'], 1, 49152.0],\n",
       " 10: [10, ['Khaled Hosseini'], 1, 59730.0],\n",
       " 11: [11, ['Veronica Roth'], 1, 101023.0],\n",
       " 12: [12,\n",
       "  ['George Orwell', 'Erich Fromm', 'CelÃ¢l Ã\\x9cster'],\n",
       "  3,\n",
       "  15172.666666666666],\n",
       " 13: [13, ['George Orwell'], 1, 35472.0],\n",
       " 14: [14,\n",
       "  ['Anne Frank', 'Eleanor Roosevelt', 'B.M. Mooyaart-Doubleday'],\n",
       "  3,\n",
       "  6941.666666666667],\n",
       " 15: [15, ['Stieg Larsson', 'Reg Keeland'], 2, 31271.5],\n",
       " 16: [16, ['Suzanne Collins'], 1, 88538.0],\n",
       " 17: [17, ['J.K. Rowling', 'Mary GrandPrÃ©', 'Rufus Beck'], 3, 12033.0],\n",
       " 18: [18, ['J.R.R. Tolkien'], 1, 15333.0],\n",
       " 19: [19, ['Suzanne Collins'], 1, 96274.0],\n",
       " 20: [20, ['J.K. Rowling', 'Mary GrandPrÃ©'], 2, 14342.5],\n",
       " 21: [21, ['Alice Sebold'], 1, 36642.0],\n",
       " 22: [22, ['J.K. Rowling', 'Mary GrandPrÃ©'], 2, 17086.0],\n",
       " 23: [23, ['J.K. Rowling', 'Mary GrandPrÃ©'], 2, 15542.0],\n",
       " 24: [24, ['J.K. Rowling', 'Mary GrandPrÃ©'], 2, 25971.0],\n",
       " 25: [25, ['Dan Brown'], 1, 41560.0],\n",
       " 26: [26, ['J.K. Rowling', 'Mary GrandPrÃ©'], 2, 13760.0],\n",
       " 27: [27, ['William Golding'], 1, 26886.0],\n",
       " 28: [28, ['William Shakespeare', 'Robert           Jackson'], 2, 7389.0],\n",
       " 29: [29, ['Gillian Flynn'], 1, 121614.0],\n",
       " 30: [30, ['Kathryn Stockett'], 1, 78204.0],\n",
       " 31: [31, ['John Steinbeck'], 1, 24642.0],\n",
       " 32: [32, ['Arthur Golden'], 1, 25605.0],\n",
       " 33: [33, ['E.L. James'], 1, 75437.0],\n",
       " 34: [34, ['Paulo Coelho', 'Alan R. Clarke'], 2, 27890.5],\n",
       " 35: [35, ['Lois Lowry'], 1, 54084.0],\n",
       " 36: [36, ['C.S. Lewis'], 1, 15186.0],\n",
       " 37: [37, ['Audrey Niffenegger'], 1, 43382.0],\n",
       " 38: [38, ['George R.R. Martin'], 1, 46205.0],\n",
       " 39: [39, ['Elizabeth Gilbert'], 1, 49714.0],\n",
       " 40: [40, ['Rick Riordan'], 1, 46006.0],\n",
       " 41: [41, ['Louisa May Alcott'], 1, 17090.0],\n",
       " 42: [42, ['Charlotte BrontÃ«', 'Michael Mason'], 2, 15606.0],\n",
       " 43: [43, ['Nicholas Sparks'], 1, 17279.0],\n",
       " 44: [44, ['Yann Martel'], 1, 42962.0],\n",
       " 45: [45, ['Sara Gruen'], 1, 55732.0],\n",
       " 46: [46, ['Markus Zusak'], 1, 93611.0],\n",
       " 47: [47, ['Ray Bradbury'], 1, 30694.0],\n",
       " 48: [48, ['Stephenie Meyer'], 1, 44020.0],\n",
       " 49: [49, ['Shel Silverstein'], 1, 9234.0],\n",
       " 50: [50, ['Cassandra Clare'], 1, 51589.0],\n",
       " 51: [51, ['Stephenie Meyer'], 1, 35216.0],\n",
       " 52: [52, ['Christopher Paolini'], 1, 18280.0],\n",
       " 53: [53, ['Douglas Adams'], 1, 20345.0],\n",
       " 54: [54, ['Aldous Huxley'], 1, 20095.0],\n",
       " 55: [55, ['Stephenie Meyer'], 1, 44550.0],\n",
       " 56: [56, ['Sue Monk Kidd'], 1, 26522.0],\n",
       " 57: [57, ['Mark Twain', 'John Seelye', 'Guy Cardwell'], 3, 4149.333333333333],\n",
       " 58: [58, ['E.B. White', 'Garth Williams', 'Rosemary Wells'], 3, 4348.0],\n",
       " 59: [59, ['Mark Haddon'], 1, 35796.0],\n",
       " 60: [60, ['Paula Hawkins'], 1, 93600.0],\n",
       " 61: [61, ['Philip Pullman'], 1, 14915.0],\n",
       " 62: [62, ['Emily BrontÃ«', 'Richard J. Dunn'], 2, 13078.5],\n",
       " 63: [63, ['Jodi Picoult'], 1, 30719.0],\n",
       " 64: [64, ['Kurt Vonnegut Jr.'], 1, 19646.0],\n",
       " 65: [65, ['Margaret Mitchell'], 1, 16050.0],\n",
       " 66: [66, ['Khaled Hosseini'], 1, 43645.0],\n",
       " 67: [67, ['Stephen Chbosky'], 1, 47116.0],\n",
       " 68: [68, ['Veronica Roth'], 1, 55873.0],\n",
       " 69: [69, ['Orson Scott Card'], 1, 38054.0],\n",
       " 70: [70,\n",
       "  ['Mary Wollstonecraft Shelley', 'Percy Bysshe Shelley', 'Maurice Hindle'],\n",
       "  3,\n",
       "  6664.333333333333],\n",
       " 71: [71, ['Stephen King'], 1, 14936.0],\n",
       " 72: [72, ['Stephenie Meyer'], 1, 39778.0],\n",
       " 73: [73, ['John Green'], 1, 47128.0],\n",
       " 74: [74, ['Helen Fielding'], 1, 8157.0],\n",
       " 75: [75, ['Jane Austen', 'Tony Tanner', 'Ros Ballaster'], 3, 3842.0],\n",
       " 76: [76, ['Louis Sachar', 'Louis Sachar'], 2, 7916.0],\n",
       " 77: [77, ['Lauren Weisberger'], 1, 8024.0],\n",
       " 78: [78,\n",
       "  ['Homer', 'Robert Fagles', 'E.V. Rieu', 'FrÃ©dÃ©ric Mugler', 'Bernard Knox'],\n",
       "  5,\n",
       "  1620.2],\n",
       " 79: [79,\n",
       "  ['Antoine de Saint-ExupÃ©ry',\n",
       "   'Richard Howard',\n",
       "   'Dom Marcos Barbosa',\n",
       "   'Melina Karakosta'],\n",
       "  4,\n",
       "  6134.25],\n",
       " 80: [80, ['Jeannette Walls'], 1, 40777.0],\n",
       " 81: [81, ['Jon Krakauer'], 1, 17299.0],\n",
       " 82: [82,\n",
       "  ['Charles Dickens', 'Richard Maxwell', 'Hablot Knight Browne'],\n",
       "  3,\n",
       "  4364.333333333333],\n",
       " 83: [83, ['Michael Crichton'], 1, 8143.0],\n",
       " 84: [84, ['Shel Silverstein'], 1, 14368.0],\n",
       " 85: [85, ['John Grisham'], 1, 4239.0],\n",
       " 86: [86, ['Elie Wiesel', 'Marion Wiesel'], 2, 11000.5],\n",
       " 87: [87, ['John Green'], 1, 42717.0],\n",
       " 88: [88, ['William Goldman'], 1, 15630.0],\n",
       " 89: [89, ['S.E. Hinton'], 1, 22662.0],\n",
       " 90: [90, ['James Dashner'], 1, 48942.0],\n",
       " 91: [91, ['Steven D. Levitt', 'Stephen J. Dubner'], 2, 6834.0],\n",
       " 92: [92, ['Frances Hodgson Burnett'], 1, 13054.0],\n",
       " 93: [93, ['Gabriel GarcÃ\\xada MÃ¡rquez', 'Gregory Rabassa'], 2, 10835.5],\n",
       " 94: [94, ['Oscar Wilde', 'Jeffrey Eugenides'], 2, 9823.5],\n",
       " 95: [95, ['E.L. James'], 1, 25287.0],\n",
       " 96: [96,\n",
       "  ['Bram Stoker', 'Nina Auerbach', 'David J. Skal'],\n",
       "  3,\n",
       "  5754.333333333333],\n",
       " 97: [97, ['Stieg Larsson', 'Reg Keeland'], 2, 15711.5],\n",
       " 98: [98, ['E.L. James'], 1, 28052.0]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. For each year of publication, determine the author that has the largest value of the shared number of reviews with a text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per rispondere a questo quesito andiamo per step:\n",
    "- per prima cosa, scriviamo una funzione chiamata _fun4_ con i seguenti parametri: <br>\n",
    "    - colonna = colonna autori di gbB <br>\n",
    "    - year = colonna degli original_publication_year di gbB <br>\n",
    "    - countReview = colonna work_text_reviews_count di gbB <br>\n",
    "\n",
    "e che segue i seguenti passi: <br>\n",
    "    -- PASSO 1: utilizziamo un ciclo for (su k) da ripetere per tutta la lunghezza della colonna _gbB['authors']_ in cui: <br>\n",
    "        1. salviamo nella lista provv gli autori di ciascun libro usando il metodo .split con separatore ',' <br> <br>\n",
    "        2. aggiungiamo alla lista del numero di autori di ciascun libro la lunghezza della colonna che splittiamo          \n",
    "            al punto 1, in modo tale da sapere quanti autori ci sono per ogni libro <br> <br>\n",
    "        3. salviamo nel dizionario 'authors_all': <br>\n",
    "            - la variabile di iterazione <br>\n",
    "            - la lista degli autori di ciascun libro <br>\n",
    "            - il numero di autori di ciascun libro <br>\n",
    "            - il valore della colonna 'work_text_reviews_count' di gbB diviso il numero di autori per ogni libro <br>\n",
    "            - l'anno di pubblicazione relativo a quel determinato libro <br> <br>\n",
    "    -- PASSO 2: eseguiamo un ciclo for (su k) da ripetere per tutta la lunghezza del dizionario 'authors_all' in cui creiamo un altro ciclo for (su j) da ripetere per tutta la lunghezza della lista degli autori di ogni riga di 'authors_all' (PASSO 3) in cui: <br>\n",
    "            - aggiungiamo alla lista 'authors_single' l'autore j-esimo della lista degli autori di ogni riga di 'authors_all' <br>\n",
    "            - aggiungiamo alla lista 'authors_year' l'anno corrispondente <br>\n",
    "            - aggiungiamo alla lista 'authors_point' il relativo punteggio <br>\n",
    "\n",
    "- successivamente: <br>\n",
    "    -- PASSO 4: chiamiamo la funzione <br>\n",
    "    -- PASSO 5: visualizziamo le liste authors_single, authors_year e authors_points <br>\n",
    "    -- PASSO 6: \n",
    "        - trasformiamo la lista authors_single in un dataframe che chiamiamo 'df' con un'unica colonna chiamata 'authors'\n",
    "        - aggiungiamo a questo dataframe la lista 'authors_years' come colonna 'anno'\n",
    "        - aggiungiamo anche la lista 'authors_points' come la colonna 'score'\n",
    "        - visualizziamo il dataframe 'df'\n",
    "    -- PASSO 7:\n",
    "        - gruppiamo il dataframe 'df' rispetto agli attributi 'authors', 'anno' e applicchiamo la funzione sum,\n",
    "            salvando il risultato nel dataframe 'df_ay'\n",
    "        - visualizziamo il dataframe 'df_ay'\n",
    "    -- PASSO 8:\n",
    "        - gruppiamo il dataframe 'df_ay' rispetto all'attributo 'anno' e applichiamo la funzione max,\n",
    "            salvando il risultato nel dataframe 'df_max' ottenendo così il risultato richiesto\n",
    "        - visuliazziamo il dataframe 'df_max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_number = []\n",
    "authors_all = {}\n",
    "authors_single = []\n",
    "authors_years = []\n",
    "authors_points = []\n",
    "\n",
    "#colonna = colonna autori di gbB\n",
    "#year = colonna degli original_publication_year di gbB\n",
    "#count review = colonna work_text_reviews_count di gbB\n",
    "def fun4(colonna, year, countReview):\n",
    "    provv = []\n",
    "    aux = []\n",
    "    \n",
    "    #Passo 1\n",
    "    for k in range(0, len(colonna)):\n",
    "        provv = colonna[k].split(sep=',')\n",
    "        authors_number.append(len(colonna[k].split(sep=',')))\n",
    "        authors_all[k] = [k, provv, authors_number[k], countReview[k]/authors_number[k], year[k]]\n",
    "\n",
    "    #Passo 2\n",
    "    for k in range(len(authors_all)):\n",
    "        \n",
    "        #Passo 3\n",
    "        for j in range(len(authors_all[k][1])):    \n",
    "            authors_single.append(authors_all[k][1][j])\n",
    "            authors_years.append(authors_all[k][4])\n",
    "            authors_points.append(authors_all[k][3])\n",
    "                                   \n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 4\n",
    "fun4(gbB['authors'], gbB['original_publication_year'], gbB['work_text_reviews_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Suzanne Collins',\n",
       " 'J.K. Rowling',\n",
       " ' Mary GrandPrÃ©',\n",
       " 'Stephenie Meyer',\n",
       " 'Harper Lee',\n",
       " 'F. Scott Fitzgerald',\n",
       " 'John Green',\n",
       " 'J.R.R. Tolkien',\n",
       " 'J.D. Salinger',\n",
       " 'Dan Brown',\n",
       " 'Jane Austen',\n",
       " 'Khaled Hosseini',\n",
       " 'Veronica Roth',\n",
       " 'George Orwell',\n",
       " ' Erich Fromm',\n",
       " ' CelÃ¢l Ã\\x9cster',\n",
       " 'George Orwell',\n",
       " 'Anne Frank',\n",
       " ' Eleanor Roosevelt',\n",
       " ' B.M. Mooyaart-Doubleday',\n",
       " 'Stieg Larsson',\n",
       " ' Reg Keeland',\n",
       " 'Suzanne Collins',\n",
       " 'J.K. Rowling',\n",
       " ' Mary GrandPrÃ©',\n",
       " ' Rufus Beck',\n",
       " 'J.R.R. Tolkien',\n",
       " 'Suzanne Collins',\n",
       " 'J.K. Rowling',\n",
       " ' Mary GrandPrÃ©',\n",
       " 'Alice Sebold',\n",
       " 'J.K. Rowling',\n",
       " ' Mary GrandPrÃ©',\n",
       " 'J.K. Rowling',\n",
       " ' Mary GrandPrÃ©',\n",
       " 'J.K. Rowling',\n",
       " ' Mary GrandPrÃ©',\n",
       " 'Dan Brown',\n",
       " 'J.K. Rowling',\n",
       " ' Mary GrandPrÃ©',\n",
       " 'William Golding',\n",
       " 'William Shakespeare',\n",
       " ' Robert           Jackson',\n",
       " 'Gillian Flynn',\n",
       " 'Kathryn Stockett',\n",
       " 'John Steinbeck',\n",
       " 'Arthur Golden',\n",
       " 'E.L. James',\n",
       " 'Paulo Coelho',\n",
       " ' Alan R. Clarke',\n",
       " 'Lois Lowry',\n",
       " 'C.S. Lewis',\n",
       " 'Audrey Niffenegger',\n",
       " 'George R.R. Martin',\n",
       " 'Elizabeth Gilbert',\n",
       " 'Rick Riordan',\n",
       " 'Louisa May Alcott',\n",
       " 'Charlotte BrontÃ«',\n",
       " ' Michael Mason',\n",
       " 'Nicholas Sparks',\n",
       " 'Yann Martel',\n",
       " 'Sara Gruen',\n",
       " 'Markus Zusak',\n",
       " 'Ray Bradbury',\n",
       " 'Stephenie Meyer',\n",
       " 'Shel Silverstein',\n",
       " 'Cassandra Clare',\n",
       " 'Stephenie Meyer',\n",
       " 'Christopher Paolini',\n",
       " 'Douglas Adams',\n",
       " 'Aldous Huxley',\n",
       " 'Stephenie Meyer',\n",
       " 'Sue Monk Kidd',\n",
       " 'Mark Twain',\n",
       " ' John Seelye',\n",
       " ' Guy Cardwell',\n",
       " 'E.B. White',\n",
       " ' Garth Williams',\n",
       " ' Rosemary Wells',\n",
       " 'Mark Haddon',\n",
       " 'Paula Hawkins',\n",
       " 'Philip Pullman',\n",
       " 'Emily BrontÃ«',\n",
       " ' Richard J. Dunn',\n",
       " 'Jodi Picoult',\n",
       " 'Kurt Vonnegut Jr.',\n",
       " 'Margaret Mitchell',\n",
       " 'Khaled Hosseini',\n",
       " 'Stephen Chbosky',\n",
       " 'Veronica Roth',\n",
       " 'Orson Scott Card',\n",
       " 'Mary Wollstonecraft Shelley',\n",
       " ' Percy Bysshe Shelley',\n",
       " ' Maurice Hindle',\n",
       " 'Stephen King',\n",
       " 'Stephenie Meyer',\n",
       " 'John Green',\n",
       " 'Helen Fielding',\n",
       " 'Jane Austen',\n",
       " ' Tony Tanner',\n",
       " ' Ros Ballaster',\n",
       " 'Louis Sachar',\n",
       " ' Louis Sachar',\n",
       " 'Lauren Weisberger',\n",
       " 'Homer',\n",
       " ' Robert Fagles',\n",
       " ' E.V. Rieu',\n",
       " ' FrÃ©dÃ©ric Mugler',\n",
       " ' Bernard Knox',\n",
       " 'Antoine de Saint-ExupÃ©ry',\n",
       " ' Richard Howard',\n",
       " ' Dom Marcos Barbosa',\n",
       " ' Melina Karakosta',\n",
       " 'Jeannette Walls',\n",
       " 'Jon Krakauer',\n",
       " 'Charles Dickens',\n",
       " ' Richard Maxwell',\n",
       " ' Hablot Knight Browne',\n",
       " 'Michael Crichton',\n",
       " 'Shel Silverstein',\n",
       " 'John Grisham',\n",
       " 'Elie Wiesel',\n",
       " ' Marion Wiesel',\n",
       " 'John Green',\n",
       " 'William Goldman',\n",
       " 'S.E. Hinton',\n",
       " 'James Dashner',\n",
       " 'Steven D. Levitt',\n",
       " ' Stephen J. Dubner',\n",
       " 'Frances Hodgson Burnett',\n",
       " 'Gabriel GarcÃ\\xada MÃ¡rquez',\n",
       " ' Gregory Rabassa',\n",
       " 'Oscar Wilde',\n",
       " ' Jeffrey Eugenides',\n",
       " 'E.L. James',\n",
       " 'Bram Stoker',\n",
       " ' Nina Auerbach',\n",
       " ' David J. Skal',\n",
       " 'Stieg Larsson',\n",
       " ' Reg Keeland',\n",
       " 'E.L. James']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passo 5.1 \n",
    "authors_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'authors_year' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-ae6524407238>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Passo 5.2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mauthors_year\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'authors_year' is not defined"
     ]
    }
   ],
   "source": [
    "#Passo 5.2\n",
    "authors_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 5.3\n",
    "authors_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 6\n",
    "df = pd.DataFrame(authors_single, columns = ['authors'])\n",
    "df['anno'] = authors_years\n",
    "df['score'] = authors_points\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 7\n",
    "df_ay = df.groupby(['authors', 'anno'], as_index=False).sum()\n",
    "df_ay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 8\n",
    "df_max = df_ay.groupby('anno').max()\n",
    "df_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Assuming that there are no errors in the ISBN fields, find the books in both datasets, and compute the difference of average rating according to the ratings and the goodratings datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Passo 1:\n",
    "    - Per prima cosa, gruppiamo il dataframe _gbR_ per l'attributo _book_id_ e ne prendiamo la media, salvando tutto nel nuovo dataframe _grB_grouppato_.\n",
    "    - Rinominiamo le colonne del dataframe in questione e visualizziamo il risultato\n",
    "2. Passo 2:\n",
    "    - Effettuiamo un merge tra i dataframes _gbR_grouppato_ e _gbB_ sull'attributo _book_id_ in modo tale da avere entrambi i datasets all'interno dello stesso dataframe --> lo chiamiamo _total_mean_\n",
    "3. Passo 3:\n",
    "    - Creiamo una nuova colonna nel dataframe _total_mean_ che chiamiamo _Difference_ data dalla differenza tra i valori della colonna _average_rating_ e la colonna _mean rating_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 1\n",
    "gbR_grouppato = gbR.groupby('book_id', as_index = False).mean()\n",
    "gbR_grouppato.columns = ['book_id', 'user_id', 'mean rating']\n",
    "gbR_grouppato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 2\n",
    "total_mean = pd.merge(gbR_grouppato, gbB, on = 'book_id')\n",
    "total_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 3\n",
    "total_mean['Difference'] = total_mean['average_rating'] - total_mean['mean rating']\n",
    "total_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Split the users dataset according to the age. One dataset contains the users with unknown age, one with age 0-14, one with age 15-24, one with age 25-34, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando che i range di età non sono tutti intervalli della stessa lunghzza, abbiamo deciso di trattare separatamente le età _NAN_, il range di età 0-14 e poi i successivi range 15-24 e così via (perchè quest'ultimi sono tutti intervalli della stessa lunghezza).\n",
    "1. Per prima cosa, estraiamo tutti gli users che hanno il valore della colonna _Age_ uguale ad NAN e li salviamo nel dataframe _users_AN_\n",
    "2. Ora selezioniamo gli users che hanno il valore della colonna _Age_ compreso tra 0 e 14 anni\n",
    "3. Per selezionare gli users negli altri range d'età creiamo due cicli FOR:\n",
    "    - nel primo la condizione del ciclo for è data dal range dall'età 15 (compresa) all'età massima esistente all'interno del dataframe, con un passo di 10 (cioè la lunghezza di ogni range che dobbiamo prendere in considerazione)\n",
    "    - nel secondo la condizione è sul range da 0 al numero di intervalli totali che abbiamo calcolato nel primo ciclo e in questo creiamo il dizionario con tutti i datasets splittati per range di età (e non _NAN_)\n",
    "4. Visualizziamo il dizionario con tutti i datasets splittati _ds_list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 1: users con age NAN\n",
    "users_AN = users[users['Age'].isnull()]\n",
    "users_AN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 2: users con age 0-14\n",
    "users_A014 = users[(users['Age'] <= 14)]\n",
    "users_A014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 3\n",
    "numInt = 0 #numero intervalli in cui devo splittare\n",
    "ds_list = {} #dizionario dei data set splittati\n",
    "fasce = [] #lista delle fasce d'età\n",
    "                                       \n",
    "for i in range(15, int(users['Age'].max()), 10):\n",
    "    numInt += 1\n",
    "    fasce.append(i)                \n",
    "#print(numInt)\n",
    "                      \n",
    "for j in range(numInt-1):\n",
    "    ds_list[j] = [j, users[(users['Age'] >= fasce[j]) & (users['Age'] < fasce[j+1]) & (users['Age'].notnull())] ]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 4\n",
    "ds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Facciamo una controprova solamente per gli users con age 15-24\n",
    "users_A1524 = users[(users['Age'] <= 24) & (users['Age'] > 14)]\n",
    "users_A1524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#che risulta essere lo stesso risultato di:\n",
    "ds_list[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Find the books that appear only in the goodbooks datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eseguiamo un merge tra i dataframes _books_ e _gbB_ sull'ISBN che è rappresentato a sinistra dalla colonna _ISBN_ e a destra dalla colonna _isbn_ e lo salviamo nel dataframe _booksOnly_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booksOnly = pd.merge(books, gbB, left_on= 'ISBN', right_on = 'isbn')\n",
    "booksOnly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Assuming that each pair (author, title) identifies a book, for each book find the number of times it appears in the books dataset. Which books appear the most times?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per prima cosa, gruppiamo il dataframe _books_ per gli attributi _'Book-Title', 'Book-Author'_. <br>\n",
    "Successivamente applichiamo la funzione count, estriamo la colonna che ci interessa (_ISBN_) e facciamo un ordinamento crescente dei valori, in modo tale da vedere il libro che compare più volte per ultimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booksC = books.groupby(['Book-Title', 'Book-Author']).count()['ISBN'].sort_values()\n",
    "booksC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Find the author with the highest average rating according to the goodbooks datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per prima cosa modifichiamo la funzione chiamata _fun_ scritta nell'esercizio 7 ad essere la funzione _fun3_, con i seguenti parametri: <br>\n",
    "    - colonna = colonna autori di gbB <br>\n",
    "    - id = colonna degli book_id di gbB <br>\n",
    "    - ar = colonna degli average rating di gbB <br>\n",
    "\n",
    "e che segue i seguenti passi: <br>\n",
    "- Per trovare la lista degli autori senza ripetizioni: <br>\n",
    "    -- PASSO 1: utilizziamo un ciclo for (su k) da ripetere per tutta la lunghezza della colonna _gbB['authors']_ in cui:\n",
    "        1. salviamo nella lista provv gli autori di ciascun libro usando il metodo .split con separatore ','\n",
    "        2. aggiungiamo alla lista del numero di autori di ciascun libro la lunghezza della colonna che splittiamo          \n",
    "            al punto 1, in modo tale da sapere quanti autori ci sono per ogni libro\n",
    "        3. salviamo nel dizionario 'authors_all':\n",
    "            - la variabile di iterazione\n",
    "            - la lista degli autori di ciascun libro\n",
    "            - il numero di autori di ciascun libro\n",
    "            - il valore della colonna 'average rating' di gbB \n",
    "     -- PASSO 2: utilizziamo un altro ciclo for (su i) all'interno del precedente per eliminare gli eventuali spazi davanti ai nomi degli autori e risolvere il problema che lo stesso autore, con o senza spazi, viene visualizzato due volte (e noi lo vogliamo ripetuto una sola volta in 'authors_list')\n",
    "\n",
    "- Per rispondere alla domanda completa: <br>\n",
    "     -- PASSO 3: utilizziamo un altro ciclo for (su j) per creare ed inizializzare il dizionario degli autori 'authors_dic' che contiene:\n",
    "             - la variabile di iterazione\n",
    "             - il nome dell'autore\n",
    "             - il valore 0, che poi verrà sostituito dalla somma degli average rating di ogni autore\n",
    "             - il valore 0, che poi verrà sostituito dal numero totale di volte in cui compare l'autore in modo tale\n",
    "                 da poter calcolarne la media\n",
    "     -- PASSO 4: utilizziamo un altro ciclo for (su j) che itera sulla lunghezza del dizionario 'authors_all' e:\n",
    "         1. PASSO 5: con un ciclo for (su i) che itera sulla lunghezza della lista degli autori di ogni riga di\n",
    "             'authors_all' che fissa ogni autore di tale lista\n",
    "         2. PASSO 6: all'interno di quest'ultimo ciclo, creiamo un ulteriore ciclo for (su k) sulla lunghezza di\n",
    "             'authors_dic' in cui se ciascun autore di 'authors_dic' è uguale all'autore fissato in precedenza\n",
    "             allora aggiorniamo nel dizionario 'authors_dic':\n",
    "             - il valore che era stato precedentemente fissato a 0 in modo tale da ottenere la somma\n",
    "                 desiderata per il calcolo della media\n",
    "             - l'ultimo valore che era stato precedentemente fissato a 0 in modo tale da avere il numero per cui\n",
    "                 dividere la somma precedente per ottenere la media\n",
    "     -- PASSO 7: con un ciclo for (su m) che itera sulla lunghezza del dizionario 'authors_dic' modifichiamo la somma ad essere la media <br>\n",
    "     -- PASSO 8:\n",
    "         1. inizializzo la lista 'authors_max' ad avere in prima posizione una stringa vuota e in seconda posizione \n",
    "             il valore 0, perchè è la lista dove salveremo l'autore che realizza il massimo richiesto e il\n",
    "             rispettivo valore del massimo\n",
    "         2. eseguiamo un altro ciclo for (su m) che itera sulla lunghezza di 'authors_dic' in modo tale da calcolare\n",
    "             il massimo valore della media calcolata precedentemente nel seguente modo: se il valore della media\n",
    "             dell'autore in 'authors_dic' è maggiore del valore massimo salvato nella lista 'authors_max' fino a\n",
    "             quel momento, allora sostituisco sia la stringa dell'autore che il valore massimo nella\n",
    "             lista 'authors_max', altrimenti non facciamo nulla\n",
    "         3. ritorniamo la lista 'authors_max'\n",
    "\n",
    "\n",
    "- Alla fine, chiamiamo la funzione (PASSO 9) e otteniamo il risultato desiderato.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_list = []\n",
    "authors_number = []\n",
    "authors_dic = {}\n",
    "authors_all = {}\n",
    "authors_max = [] #dove metto l'autore con il max\n",
    "\n",
    "\n",
    "#colonna = colonna authors di gbB\n",
    "#id = colonna degli id-books di gbB\n",
    "#ar = colonna average rating\n",
    "\n",
    "def fun3(colonna, id, ar):\n",
    "    provv = []\n",
    "    aux = []\n",
    "    #cerco ogni autore in ciascuna riga\n",
    "    \n",
    "    #Passo 1\n",
    "    for k in range(0, len(colonna)):\n",
    "        provv = colonna[k].split(sep=',')\n",
    "        authors_number.append(len(colonna[k].split(sep=',')))\n",
    "        authors_all[k] = [k, provv, authors_number[k],  ar[k]]\n",
    "        \n",
    "        #Passo 2\n",
    "        for i in range(len(provv)):\n",
    "            provv[i] = provv[i].strip()\n",
    "            if provv[i] not in authors_list:\n",
    "                 authors_list.append((provv[i]))\n",
    "    #Passo 3    \n",
    "    for j in range(len(authors_list)):\n",
    "        authors_dic[j] = [j, authors_list[j], float(0), 0]\n",
    "        \n",
    "    #Passo 4\n",
    "    for j in range(len(authors_all)):\n",
    "        \n",
    "        #Passo 5\n",
    "        for i in range(len(authors_all[j][1])):\n",
    "            fisso = authors_all[j][1][i]\n",
    "            \n",
    "            #Passo 6\n",
    "            for k in range(len(authors_dic)):\n",
    "                if (authors_dic[k][1] ==  fisso):\n",
    "                    authors_dic[k][2] = authors_dic[k][2] +float(authors_all[j][3])\n",
    "                    authors_dic[k][3] = authors_dic[k][3] + 1 \n",
    "                    \n",
    "    #Passo 7               \n",
    "    for m in range(len(authors_dic)):\n",
    "        authors_dic[m][2] = authors_dic[m][2]/authors_dic[m][3]\n",
    "    \n",
    "    #Passo 8 \n",
    "    authors_max = ['', 0]\n",
    "    for m in range(len(authors_dic)):\n",
    "        if (authors_dic[m][2] >= authors_max[1]):\n",
    "            authors_max = [authors_dic[m][1], authors_dic[m][2]]\n",
    "            \n",
    "    return authors_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 9\n",
    "fun3(gbB['authors'], gbB['book_id'], gbB['average_rating'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
